{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMc1xN3WkrKqjSrU2P0FSsb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bhavika67/NLP/blob/main/Tokenizing_Text%2C_Removing_Stop_Words_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tokenizing Text, Removing Stop Words."
      ],
      "metadata": {
        "id": "zJ6OIXXWpeBB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Removing Stop Words**"
      ],
      "metadata": {
        "id": "wCmqR4I6piss"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KEYCKBUQpaVK",
        "outputId": "54a17ebf-8add-4cd3-8459-bb3c3b72e55e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                               tweet\n",
            "0                        This is introduction to NLP\n",
            "1              It is likely to be useful, to people \n",
            "2             Machine learning is the new electrcity\n",
            "3  There would be less hype around AI and more ac...\n",
            "4                           python is the best tool!\n",
            "5                                R is good langauage\n",
            "6                                   I like this book\n",
            "7                        I want more books like this\n"
          ]
        }
      ],
      "source": [
        "text=['This is introduction to NLP',\n",
        "      'It is likely to be useful, to people ',\n",
        "      'Machine learning is the new electrcity',\n",
        "      'There would be less hype around AI and more action going forward',\n",
        "      'python is the best tool!',\n",
        "      'R is good langauage',\n",
        "      'I like this book',\n",
        "      'I want more books like this']\n",
        "#convert list to data frame\n",
        "import pandas as pd\n",
        "df = pd.DataFrame({'tweet':text})\n",
        "print(df)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#install and import libraries\n",
        "!pip install nltk\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "#remove stop words\n",
        "stop = stopwords.words('english')\n",
        "df['tweet'] = df['tweet'].apply(lambda x: \" \".join(x for x in x.split() if x not in stop))\n",
        "df['tweet']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 456
        },
        "id": "XTgFEUovpvS3",
        "outputId": "e2e1b1e7-db08-4508-9126-a1baf134f6b2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2024.9.11)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.5)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0                                This introduction NLP\n",
              "1                             It likely useful, people\n",
              "2                      Machine learning new electrcity\n",
              "3    There would less hype around AI action going f...\n",
              "4                                    python best tool!\n",
              "5                                     R good langauage\n",
              "6                                          I like book\n",
              "7                                    I want books like\n",
              "Name: tweet, dtype: object"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>This introduction NLP</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>It likely useful, people</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Machine learning new electrcity</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>There would less hype around AI action going f...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>python best tool!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>R good langauage</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>I like book</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>I want books like</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> object</label>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Tokenizing**\n",
        "\n",
        "Tokenization is the process of breaking down text into smaller units called tokens. These tokens can be words, phrases, or even individual characters depending on your needs"
      ],
      "metadata": {
        "id": "60inXrAmqTiF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Using the split() method**"
      ],
      "metadata": {
        "id": "o0IHwBJHqrM8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"This is a sample sentence.\"\n",
        "tokens = text.split()\n",
        "print(tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v_C3Da9zqt0u",
        "outputId": "12cd984b-4edd-4ca1-a31a-12cc50136447"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['This', 'is', 'a', 'sample', 'sentence.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Using the re module (Regular Expressions):**"
      ],
      "metadata": {
        "id": "yML4AkLnq7Um"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "text = \"This is a sentence! It has punctuation.\"\n",
        "tokens = re.findall(r'\\w+', text)  # Find all word characters\n",
        "print(tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mg-zgR6mrCGb",
        "outputId": "3f6ee01a-186d-47e4-fd87-cde6e7088215"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['This', 'is', 'a', 'sentence', 'It', 'has', 'punctuation']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Using NLTK (Natural Language Toolkit):**"
      ],
      "metadata": {
        "id": "mWnNMlzCrG72"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "nltk.download('punkt')\n",
        "text = \"This is a sentence. It has punctuation!\"\n",
        "tokens = word_tokenize(text)\n",
        "print(tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9bfJ9vrZrrRR",
        "outputId": "e8f6100b-1bd2-4d31-85b2-e4759d2e20b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['This', 'is', 'a', 'sentence', '.', 'It', 'has', 'punctuation', '!']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Using SpaCy:**"
      ],
      "metadata": {
        "id": "wwA2_Gddr84d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "text = \"This is a sentence. It has punctuation!\"\n",
        "doc = nlp(text)\n",
        "tokens = [token.text for token in doc]\n",
        "print(tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UArN6IshsBWi",
        "outputId": "876fa21e-4a0e-4a48-ce61-3338f9373c3e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['This', 'is', 'a', 'sentence', '.', 'It', 'has', 'punctuation', '!']\n"
          ]
        }
      ]
    }
  ]
}